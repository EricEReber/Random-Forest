Representation of the matrix

When subsampling features of the design matrix we extract m of p features, however, we are unsure how to represent these

alternative 1 (current representation)

Remove columns, remaining columns are unordered. How can the tree know which feature (column) we are refering to? Perhaps each tree will learn one unique design matrix and ones that will be prediced must be formatted appropriatly? CHECK deep learning from scratch? Formatting of random procedure must then be remembered, makes no sense..

alternative 2 (zero-columns)

Zero out columns, leaves columns ordered and ensures same design matrix can be sent in to all trees. Actually, all trees will have the same sized design matrix with either representation, but with this representation no preprocessing from -AAAAAAAAAAH we would have to know which columns to zero out anyway. This problems seems to strictly be with the RandomForest class, not the DecisionTree class. Zeroing out columns seems like a worse idea because we have all the drawbacks of alternative 1, but additionally it would be less compunationally efficient and would potentially mess up the entropy/gini calculations (unless we do some clunky but maybe actually based exceptions).


The main problem seems to now be, how do we remember for each tree which columns to remove? Well, how about we have a dictionary with num_trees keys, where n accesses a tuple (or something) of the columns which were kept! This should solve everything no? We obtain tuples during fitting, they are stored in global dict alongside trees in global list. When looping through trees to predict we just call -honestly just use a list, its sorted in parallel to need to do keys. Nested list or something. This seems based.
